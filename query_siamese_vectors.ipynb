{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded success\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from GPT2 import GPT2Model, GPT2Tokenizer\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "device = 'cuda' #'cuda'\n",
    "\n",
    "\n",
    "def tokenize_input(inputStr, tokenizer, seq_length=1024):\n",
    "    pad_id = tokenizer.encoder['<pad>']\n",
    "    tokenized_sentence = tokenizer.encode(inputStr)[:seq_length-20]\n",
    "    tokens = tokenized_sentence\n",
    "    token_length = len(tokens)\n",
    "    tokens.extend([pad_id] * (seq_length - token_length))\n",
    "    tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "    return tokens.reshape(1,1024), [token_length]\n",
    "\n",
    "tokenizer = GPT2Tokenizer(\n",
    "    'GPT2/bpe/vocab.json',\n",
    "    'GPT2/bpe/chinese_vocab.model',\n",
    "    max_len=512)\n",
    "    \n",
    "class LayerNorm(nn.Module):\n",
    "    r\"\"\"\n",
    "    Layer normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, eps=1e-5):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.weight * x + self.bias\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear = nn.Linear(n_in, n_out)\n",
    "        self.layer_norm = LayerNorm(n_out)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPT2_SIMILARITY(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GPT2_SIMILARITY, self).__init__()\n",
    "        \n",
    "        self.GPT2model = GPT2Model(\n",
    "            vocab_size=30000,\n",
    "            layer_size=12,\n",
    "            block_size=1024,\n",
    "            embedding_dropout=0.0,\n",
    "            embedding_size=768,\n",
    "            num_attention_heads=12,\n",
    "            attention_dropout=0.0,\n",
    "            residual_dropout=0.0\n",
    "        )\n",
    "\n",
    "        self.mlp =  MLP(30000, 256)\n",
    "\n",
    "    def forward(self, x, length):\n",
    "        x = self.GPT2model(x)\n",
    "        classify = []\n",
    "        for i in range(len(length)):\n",
    "            classify.append(x[i, length[i]].view(-1))\n",
    "        classify = torch.stack(classify)\n",
    "        classify = self.mlp(classify)\n",
    "        return classify\n",
    "\n",
    "    def get_vector_0(self, x, length):\n",
    "        x = self.GPT2model(x)\n",
    "        return x[0, length[0]]\n",
    "\n",
    "\n",
    "model = torch.load('../models/similarity_0.pth', map_location='cpu')\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "print('loaded success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_chinese(string):\n",
    "    \"\"\"\n",
    "    检查整个字符串是否包含中文\n",
    "    :param string: 需要检查的字符串\n",
    "    :return: bool\n",
    "    \"\"\"\n",
    "    for ch in string:\n",
    "        if u'\\u4e00' <= ch <= u'\\u9fa5':  # \\u9fff\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364\n",
      "要点二:经营范围 生物技术开发、技术咨询、技术转让、技术服务;经济信息咨询(不含行政许可的项目);工程招标及代理;货物进出口、技术进出口、代理进出口;销售金属材料、化工产品(不含一类易制毒品及危险化学品)、玻璃容器;会议服务;承办展览展示活动;设计、制作、代理、发布广告;生产重组蛋白;生产培养基、填料;生产生物试剂盒。。要点三:重组蛋白等关键生物试剂产品及技术服务 公司是一家专业提供重组蛋白等关键生物试剂产品及技术服务的高新技术企业,助力全球生物医药公司、生物科技公司和科研机构等进行生物药、细胞免疫治疗及诊断试剂的研发与生产。公司主要产品及服务应用于肿瘤、自身免疫疾病、心血管病、传染病等疾病的药物早期发现及验证、药物筛选及优化、诊断试剂开发及优化、临床前实验及临床试验、药物生产过程及工艺控制(CMC)等研发及生产环节。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['口服',\n",
       " '肝',\n",
       " '抗',\n",
       " '异',\n",
       " '毒',\n",
       " '有效',\n",
       " '复',\n",
       " '对',\n",
       " '类',\n",
       " '糖',\n",
       " '单',\n",
       " '胶囊',\n",
       " '酸',\n",
       " '红',\n",
       " '滴',\n",
       " '多',\n",
       " '苦',\n",
       " '双',\n",
       " '和',\n",
       " '过敏']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = '。'.join(data.iloc[11]['info'].split('\\n')[1:3])\n",
    "\n",
    "print(len(input))\n",
    "print(input)\n",
    "\n",
    "tokens, token_length = tokenize_input(input, tokenizer, seq_length=1024)\n",
    "output = model.get_vector_0(tokens.to(device), token_length)\n",
    "vector = output.detach().cpu().numpy()\n",
    "\n",
    "topk = np.argsort(-vector)\n",
    "\n",
    "keywords = [tokenizer.decode(i) for i in topk.tolist() if is_chinese(tokenizer.decode(i))]\n",
    "\n",
    "keywords[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv('../data/stock_list_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stockName</th>\n",
       "      <th>stockCode</th>\n",
       "      <th>indvInduCode</th>\n",
       "      <th>indvInduName</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>明阳智能</td>\n",
       "      <td>601615</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>风电设备</td>\n",
       "      <td>要点一:所属板块 风电设备 广东板块 标准普尔 富时罗素 MSCI中国 沪股通 上证380 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>帅丰电器</td>\n",
       "      <td>605336</td>\n",
       "      <td>456.0</td>\n",
       "      <td>家电行业</td>\n",
       "      <td>要点一:所属板块 家电行业 浙江板块\\n要点二:经营范围 制造、销售:集成灶、吸排油烟机、燃...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>兆易创新</td>\n",
       "      <td>603986</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>半导体</td>\n",
       "      <td>要点一:所属板块 半导体 北京板块 百元股 标准普尔 富时罗素 MSCI中国 沪股通 上证1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>鼎龙股份</td>\n",
       "      <td>300054</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>电子化学品</td>\n",
       "      <td>要点一:所属板块 电子化学品 湖北板块 富时罗素 创业板综 深股通 融资融券 预盈预增 深成...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>拓普集团</td>\n",
       "      <td>601689</td>\n",
       "      <td>481.0</td>\n",
       "      <td>汽车零部件</td>\n",
       "      <td>要点一:所属板块 汽车零部件 浙江板块 标准普尔 富时罗素 MSCI中国 沪股通 中证500...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stockName  stockCode  indvInduCode indvInduName  \\\n",
       "0      明阳智能     601615        1032.0         风电设备   \n",
       "1      帅丰电器     605336         456.0         家电行业   \n",
       "2      兆易创新     603986        1036.0          半导体   \n",
       "3      鼎龙股份     300054        1039.0        电子化学品   \n",
       "4      拓普集团     601689         481.0        汽车零部件   \n",
       "\n",
       "                                                info  \n",
       "0  要点一:所属板块 风电设备 广东板块 标准普尔 富时罗素 MSCI中国 沪股通 上证380 ...  \n",
       "1  要点一:所属板块 家电行业 浙江板块\\n要点二:经营范围 制造、销售:集成灶、吸排油烟机、燃...  \n",
       "2  要点一:所属板块 半导体 北京板块 百元股 标准普尔 富时罗素 MSCI中国 沪股通 上证1...  \n",
       "3  要点一:所属板块 电子化学品 湖北板块 富时罗素 创业板综 深股通 融资融券 预盈预增 深成...  \n",
       "4  要点一:所属板块 汽车零部件 浙江板块 标准普尔 富时罗素 MSCI中国 沪股通 中证500...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [04:44<00:00,  7.58it/s]\n"
     ]
    }
   ],
   "source": [
    "all = []\n",
    "for i in tqdm(range(len(data))):\n",
    "    item = data.iloc[i]\n",
    "    info = '。'.join(item['info'].split('\\n')[1:3]) # 要点二和要点三\n",
    "    tokens, token_length = tokenize_input(info, tokenizer, seq_length=1024)\n",
    "    output = model(tokens.to(device), token_length)\n",
    "    vector = output[0].detach().cpu().numpy()\n",
    "\n",
    "    all.append(\n",
    "        {\n",
    "            'stockName': item['stockName'],\n",
    "            'stockCode': str(item['stockCode']).zfill(6),\n",
    "            'indvInduName': item['indvInduName'],\n",
    "            'indvInduCode': int(item['indvInduCode']),\n",
    "            'info': info,\n",
    "            'vector': vector,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./data_ignore/vectors_siamese.pkl','wb') as f:\n",
    "    pickle.dump(all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15d51a80c8523c0d895fb35f7540c75abd446de76bbe33959811c01c8d0e84fa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gpt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
